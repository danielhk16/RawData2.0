# -*- coding: utf-8 -*-
"""
Created on Wed May 23 10:51:15 2018

@author: jm01 (Chonglou)

@ Completed on ???
"""

# -*- coding: utf-8 -*-
"""
==========================================================
This script is work to generate lab data 2.0(USER WEB LOG AND TRANSACTIONS)
==========================================================

INFO:
# Total Running Time: 10 mins for each sales day
# Table Structure Generated: []
# Total Rows Generated: depends...

RESOURCES(MySQL):
originaldata.customer
originaldata.cust_property
originaldata.prod_online
originaldata.demo_tmp_dim_product_purchases
originaldata.demand
originaldata.noise
originaldata.ad_click
originaldata.advertising
originaldata.promo_received
originaldata.promotion1
originaldata.inventory
originaldata.inventory_transactions
"""
# !!!!!Please Make Sure Available Memory Have At Least 32G

# import sys
from tqdm import tqdm
import csv
import math
import random
import numpy as np
import pandas as pd
import pymysql.cursors
from datetime import *
import time 
from sqlalchemy import create_engine
from copy import deepcopy
# deepcopy: forces objects to be copied in memory, so that methods called on the new objects are not applied to the source object.

time_start=time.time()
print('Start at', time.strftime("%H:%M:%S") )

# global variables
oridata = create_engine(
    'mysql+pymysql://jm01:Arc@201801@rm-uf6f7sl8tkx54io559o.mysql.rds.aliyuncs.com:3306/originaldata')

start_dt = date(2011, 5, 18)
print("start_dt is", start_dt)

'''âš ï¸ please modify the end_dt for smoke testing'''
end_dt = date(2019, 12, 31)
print("end_dt is", end_dt)

# nominate depend tables and their date keys in case of any change in the database
dp_t1 = 'customer'
dp_t2, dp_t2_dtkey = 'cust_property', 'modify_date'
dp_t3, dp_t3_dtkey = 'ad_click', 'ad_click_date'
dp_t4, dp_t4_begindt, dp_t4_enddt = 'advertising', 'ad_begin_date', 'ad_end_date'
dp_t5, dp_t5_dtkey = 'promo_received', 'send_date'
dp_t6, dp_t6_begindt, dp_t6_enddt = 'promotion', 'promo_begin_date', 'promo_end_date'
dp_t7, dp_t7_dtkey = 'prod_online', 'refresh_date'
dp_t8, dp_t8_dtkey = 'demo_inventory', 'Date'
dp_t9, dp_t9_dtkey = 'demo_inventory_trans', 'transaction_date'
dp_t10, dp_t10_dtkey = 'demand', 'date'
dp_t11, dp_t11_dtkey = 'noise', 'date'
dp_t12 = 'demo_tmp_dim_product_purchases'
dp_t13 = 'product'

dp_t14 = 'sales_order_details'
dp_t15 = 'sales_order'    
result_tbl = 'sales_order'
result_tbl_dtkey = 'date'

def main():

    # find refresh date
    refresh_dt = findRefresh_dt(oridata, result_tbl, result_tbl_dtkey)
    # QA
    print("refresh_dt begins at", refresh_dt)

    # å¼€å§‹æ¯ä¸€å¤©çš„å¾ªç¯
    while refresh_dt <= end_dt:

        # æ‰¾åˆ°åº“å­˜è¡¨æœ€å¤§æ—¥æœŸ
        invt_maxdt = findMax_dt(oridata, dp_t8, dp_t8_dtkey)

        # æ‰¾åˆ°éœ€æ±‚è¡¨æœ€å¤§æ—¥æœŸ
        dmd_maxdt = findMax_dt(oridata, dp_t10, dp_t10_dtkey)

        # åˆ¤æ–­åº“å­˜è¡¨å’Œéœ€æ±‚è¡¨æ˜¯å¦èƒ½å¤Ÿæ»¡è¶³å½“å¤©ç”Ÿäº§æ‰€éœ€çš„æ•°æ®
        if refresh_dt <= invt_maxdt + timedelta(days=1) and refresh_dt <= dmd_maxdt:

            # PART 1 ======================================================================================

            # 1.1 å¼€å§‹ç”Ÿæˆ3ä¸ªdf
            print("Dataframes production for {0} begins".format(refresh_dt))

            # 1.2 æŠ½å–3è¡¨æ ¼å½“å¤©çš„æ•°æ®
            df_demand = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} = '{2}' """.format(dp_t10, dp_t10_dtkey, refresh_dt), oridata)
            df_noise = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} = '{2}' """.format(dp_t11, dp_t11_dtkey, refresh_dt), oridata)
            df_ads_click = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} = '{2}' """.format(dp_t3, dp_t3_dtkey, refresh_dt), oridata)

            # 1.3 æ·»åŠ æˆ–è¡¥å……æ–°åˆ—ï¼šOrigin æµè§ˆæ¥æº,first_buy_mark è´­ä¹°æ¦‚ç‡æ ‡è®°,land_page æµè§ˆå¼€å§‹é¡µ
            df_demand['prob_origin'] = np.random.random(df_demand.shape[0])
            df_demand['origin'] = np.where(
                df_demand['prob_origin'] > 0.2, 'direct', 'search')
            df_demand['land_page'] = 'home_page'
            df_noise['prob_origin'] = np.random.random(df_noise.shape[0])
            df_noise['origin'] = np.where(
                df_noise['prob_origin'] > 0.3, 'direct', 'search')
            df_noise['land_page'] = 'home_page'
            df_ads_click['origin'] = 'ads'
            df_ads_click['first_buy_mark'] = 0
            df_ads_click['land_page'] = 'ads_page'
            # QA
            print('row of df_ads_click is ', len(df_ads_click))

            # PART 2 ======================================================================================

            # 2.1 æŠ½å–å¹¶é“¾æ¥ å¹¿å‘Šè¡¨ å’Œ äº§å“è´­ä¹°åŸºå‡†è¡¨ ä¸­çš„ quantityå­—æ®µï¼Œå¾—åˆ°å¹¿å‘Šäº§å“è¡¨

            # dp_t4, dp_t4_begindt, dp_t4_enddt = 'advertising', 'ad_begin_date', 'ad_end_date'
            # dp_t12 = 'demo_tmp_dim_product_purchases'

            sql_ads_quantity = """
                SELECT a.*, b.purchase_quantity
                FROM {0} as a LEFT JOIN {1} as b
                ON a.product_key = b.product_key
                WHERE a.{2} <= '{4}' AND a.{3} >= '{4}'
                """.format(dp_t4, dp_t12, dp_t4_begindt, dp_t4_enddt, refresh_dt)
            df_ads_quantity = pd.read_sql(sql_ads_quantity, oridata)

            '''å°é—®é¢˜ï¼šè¿™é‡Œfillnaæ˜¯ç”¨æ¥ä¿è¯ å¹¿å‘Šè¡¨ ä¸­çš„äº§å“ ä¸åœ¨ äº§å“è´­ä¹°åŸºå‡†è¡¨ çš„æƒ…å†µä¸‹ï¼Œpurchase_quantity ä¸ºç©ºå€¼'''
            df_ads_quantity['purchase_quantity'].fillna(value=1, inplace=True)
            # QA
            print('row of df_ads_quantity is ', len(df_ads_quantity))

            # 2.2 é“¾æ¥å¹¿å‘Šç‚¹å‡»è¡¨å’Œå¹¿å‘Šäº§å“è¡¨,äº§ç”Ÿç¬›å¡å°”ç§¯,ä½¿æ¯ä¸€ä¸ªé¡¾å®¢éƒ½æœ‰Nä¸ªäº§å“
            df_ads = pd.merge(df_ads_click, df_ads_quantity[['advertising_key', 'product_key', 'purchase_quantity']],
                              how='left', on='advertising_key')
            # QA
            print('row of df_ads is ', len(df_ads))

            # PART 3 ======================================================================================
            # å°†demand,noiseå’Œadsçš„åˆ—åç»Ÿä¸€ï¼Œç„¶ååˆå¹¶3å¼ è¡¨
            df_demand.rename(columns={'calendar_date': 'date'}, inplace=True)
            df_noise.rename(columns={'calendar_date': 'date'}, inplace=True)
            df_ads.rename(columns={'ad_click_date': 'date',
                                   'purchase_quantity': 'quantity'}, inplace=True)
            df_visits = df_demand.append([df_noise, df_ads], ignore_index=True)
            # QA
            print('row of df_noise is ', len(df_noise))
            print('row of df_demand is ', len(df_demand))
            print('row of df_visits is ', len(df_visits))

            # PART 4 ======================================================================================
            # æŠ½å–loyalty
            print('fetching cust_property ... ')
            df_cust_property = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} IS NULL or {1} <= '{2}' """.format(dp_t2, dp_t2_dtkey, refresh_dt), oridata)
            df_cust_property = df_cust_property[[
                'customer_key', 'cust_loyalty', 'modify_date']]
            df_cust_property.sort_values(
                by='modify_date', ascending=True, inplace=True)  # åªä¿ç•™æœ€æ–°çš„loyaltyè®°å½•
            df_cust_property = df_cust_property.groupby('customer_key').tail(1)

            print('merging loyalty ... ')  
            # é“¾æ¥ loyalty åˆ° df_visits
            df_visits = pd.merge(df_visits, df_cust_property[[
                                 'customer_key', 'cust_loyalty']], how='left', on='customer_key')

            '''å·²è§£å†³ï¼šå½“å¤©çš„é¡¾å®¢è¡¨ä¸­æ²¡æœ‰æµ‹è¯•æ•°æ®çš„é‚£äº›é¡¾å®¢ï¼Œæ‰€ä»¥ä¸‹é¢è¿™è¡Œæ˜¯ç”¨æ¥ä¿è¯loyaltyè¿™ä¸€åˆ—æ— ç©ºå€¼'''
            '''ä¸‹é¢è¿™è¡Œæµ‹è¯•ç”¨ï¼Œç”¨æ¥è¡¥é½ç©ºå€¼ï¼Œdemandè¡¨æ”¹å®Œä¹‹åæ³¨é‡Šæ‰ï¼Œå†æµ‹è¯•ä¸€æ¬¡'''
            # df_visits['cust_loyalty'] = df_visits['cust_loyalty'].apply(
            #     lambda x: np.random.random() if pd.isnull(x) else x)

            # QA
            print('row of df_visits is ', len(df_visits))

            # PART 5 ======================================================================================
            # æŠ½å–ä»·æ ¼ price

            # dp_t7, dp_t7_dtkey = 'prod_online', 'refresh_date'

            print('fetching price ... ')
            df_price = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} <= '{2}' """.format(dp_t7, dp_t7_dtkey, refresh_dt), oridata)
            df_price = df_price[['product_key', 'price', 'refresh_date']]
            df_price.sort_values(
                by='refresh_date', ascending=True, inplace=True)  # åªä¿ç•™æœ€æ–°çš„priceè®°å½•
            df_price = df_price.groupby('product_key').tail(1)
            # print("df_price's first 5 rows is ", df_price.head())

            print('merging price ... ')  # é“¾æ¥ df_visits
            df_visits = pd.merge(
                df_visits, df_price[['product_key', 'price']], how='left', on='product_key')

            '''å·²è§£å†³:å½“å¤©first_buy_markä¸º1çš„äººéœ€æ±‚çš„äº§å“ï¼Œå¿…é¡»å·²ç»ä¸Šæ¶ï¼Œå¦åˆ™priceé‚£ä¸€åˆ—ä¼šå‡ºç°ç©ºå€¼'''
            '''ä¸‹é¢è¿™è¡Œç”¨æ¥è¡¥ç©ºå€¼ï¼Œæ–¹ä¾¿buy_scoreè®¡ç®—'''
            df_visits['price'].fillna(value=0, inplace=True)


            # QA
            print('row of df_visits is ', len(df_visits))

            # PART 6 ======================================================================================
            # è®¡ç®—é¡¾å®¢çŠ¶æ€ Status

            print('fetching customer ... ')
            df_cust = pd.read_sql(
                """SELECT id,customer_key,cust_first_order_date,close_date,return_date
                FROM {0} """.format(dp_t1), oridata)

            print('calculating status ... ')
            df_cust_status = cust_seg(df_cust, refresh_dt)

            print('merging status ... ')  # é“¾æ¥ df_visits
            df_visits = pd.merge(df_visits, df_cust_status,
                                 how='left', on='customer_key')

            # å½“å¤©çš„éœ€æ±‚è¡¨ä¸­æ²¡æœ‰çŠ¶æ€çš„é‚£äº›é¡¾å®¢ï¼Œè¯´æ˜ä»–ä»¬å½“å¤©ä¸èƒ½è¿›è¡Œ è´­ä¹°ï¼Œå¦åˆ™å’Œä»–ä»¬çš„statusè®¡ç®—ç»“æœä¼šå‘ç”Ÿå†²çª
            # éœ€è¦å°†ä»–ä»¬çš„first_buy_markæ”¹ä¸º-1
            df_visits['cust_status'].fillna(value=0, inplace=True)
            df_visits['first_buy_mark'] = df_visits.apply(lambda row: fbm_modify(row), axis=1)
            df_visits['visit_key'] = range(1, len(df_visits) + 1)

            # QA
            print('row of df_visits is ', len(df_visits))

            # PART 7 ======================================================================================
            # æ ¹æ®é¡¾å®¢æ”¶åˆ°çš„ä¿ƒé”€ï¼Œæ–°å¢ä¿ƒé”€ä¿¡æ¯ï¼ˆç§ç±»ã€åŠ›åº¦ã€æ—¶é—´ç­‰ï¼‰

            # dp_t5, dp_t5_dtkey = 'promo_received', 'send_dt'
            # dp_t6, dp_t6_begindt, dp_t6_enddt = 'promotion1', 'promo_begin_date', 'promo_end_date'

            # è·å–å½“å¤©çš„æœ‰æ•ˆæœŸå†…ä¿ƒé”€è¡¨
            print('fetching promotion ... ')
            df_promotion = pd.read_sql(
                """SELECT *
                FROM {0}
                WHERE '{1}' BETWEEN {2} AND {3} """.format(dp_t6, refresh_dt, dp_t6_begindt, dp_t6_enddt), oridata)

            # è·å–å½“å¤©é¡¾å®¢æŒæœ‰çš„æœ‰æ•ˆæœŸå†…ä¿ƒé”€å·
            print('fetching promo_received ...')
            df_promo_received = pd.read_sql(
                """SELECT * FROM {0} WHERE {1} <= '{2}' """.format(dp_t5, dp_t5_dtkey, refresh_dt), oridata)

            # é“¾æ¥ promo å’Œ promo_received
            print('merging customers, promotion products and discount types ... ')
            df_promo = pd.merge(df_promotion, df_promo_received,
                                how='inner', on='promo_key')
            # QA
            print('row of df_promo is ', len(df_promo))
            
            # é“¾æ¥ df_visits ä¸­çš„å•†å“ä¿¡æ¯
            print('merging promotions to df_visits: visit_keyï¼Œcustomers and product info... ')
            # df_visits = pd.merge(df_visits[['visit_key', 'customer_key', 'product_key', 'quantity', 'price']], df_promo, how='left', on=['customer_key', 'product_key'])
            df_visits = pd.merge(df_visits, df_promo, how='left', on=['customer_key', 'product_key'])
            # ç±»å‹è½¬æ¢å’Œè®¡ç®—
            df_visits['discount_type'] = df_visits['discount_type'].astype(str)
            df_visits['quantity'] = df_visits['quantity'].astype(float)
            df_visits['price'] = df_visits['price'].astype(float)
            df_visits['fcp_treatment'] = df_visits['fcp_treatment'].apply(trans_into_dict)
            df_visits['bp_treatment'] = df_visits['bp_treatment'].apply(trans_into_dict)
            df_visits['mp_treatment'] = df_visits['mp_treatment'].apply(trans_into_dict)
            df_visits['sales'] = df_visits['quantity'] * df_visits['price']
            # QA
            print('row of df_visits is ', len(df_visits))

            # åœ¨df_visitsä¸­ï¼Œæ ¹æ®ä»·æ ¼ã€æ•°é‡å’Œä¿ƒé”€ç±»å‹ï¼Œè®¡ç®—å¹¶æ–°å¢sales, adj_sales å’Œ adj_quantity
            print('calculating adjusted sales and quantities ... ')
            tqdm.pandas()
            df_visits = df_visits.progress_apply(lambda row: promo_affects(row), axis=1)
            # df_cpp_adj = promo_affects(df_cpp)
            # df_cpp_adj = df_cpp_adj[['visit_key', 'sales', 'promo_key', 'discount_type', 'adj_quantity', 'adj_sales']]

            # # é“¾æ¥ df_visits
            # print('merging adjusted sales and quantities to df_visits ... ')
            # df_visits = pd.merge(df_visits, df_cpp_adj,
            #                      how='left', on='visit_key')
            # QA
            # print('row of df_visits is ', len(df_visits))

            # PART 8 ======================================================================================

            # åˆ¤æ–­é¡¾å®¢æ˜¯å¦æ„¿æ„ä¸‹å•
            print('calculating buying scores... ')
            df_visits = buy_decision(df_visits)
            # QA
            print('row of df_visits is ', len(df_visits))

            # PART 9 ======================================================================================
            # åˆ¤æ–­åº“å­˜é‡æ˜¯å¦èƒ½å®Œæˆè®¢å•

            # 9.1 æŠ“å–äº§å“éƒ¨é—¨ç¼–ç  department code
            # dp_t13 = 'product'
            print('fetching department ... ')
            df_department = pd.read_sql(
                """SELECT DISTINCT product_key,department_cd FROM {0} """.format(dp_t13), oridata)

            # é“¾æ¥ department_cd åˆ° df_visits
            print('merging department to df_visits ... ')
            df_visits = pd.merge(df_visits, df_department,
                                 how='left', on='product_key')
            # QA
            print('row of df_visits is ', len(df_visits))

            # 9.2 ç”Ÿæˆè®¢å•
            df_visits, df_allp_invt_Comb = orderGenerate(df_visits,refresh_dt, df_department, df_price) 
            # QA
            print('row of df_visits is  ', len(df_visits))


            '''ç½‘é¡µè¡¨éƒ¨åˆ† å¼€å§‹'''
            # PART 10 ======================================================================================
            # ä»è¿™é‡Œå¼€å§‹ ä»¥ df_visits ä¸ºåŸºç¡€ ï¼Œç”Ÿæˆdf_orderså³è®¢å•è¡¨ å’Œ df_sessionså³ç½‘é¡µæµè§ˆè¡¨
            '''ç½‘é¡µè¡¨éƒ¨åˆ† ç»“æŸ'''

            # 10.1 åˆå¹¶åŒä¸€é¡¾å®¢çš„å½“æ—¥è®¢å• 

            # ç­›é€‰å‡ºæ‰€æœ‰è®¢å•
            df_orders = deepcopy(df_visits.loc[df_visits['trans_done'] == 1, :])
            print('row of df_orders is  ', len(df_orders))
            df_orders = df_orders.reset_index(drop=True)
            df_orders = df_orders[['visit_key', 'date', 'time_stamp', 'customer_key',
                       'product_key', 'promo_key',  'adj_sales', 'adj_quantity']]
            # è®¡ç®—å®é™…äº¤æ˜“å•ä»·
            df_orders['adj_price'] = df_orders['adj_sales']/df_orders['adj_quantity']

            # ç”Ÿæˆorder_key
            df_orders['dt_key'] = df_orders['date'].apply(to_integer)
            df_orders['order_key'] = df_orders.apply(lambda row: orderkey(row), axis=1)

            # ç”Ÿæˆä¸€ä¸ªæ»¡è¶³ï¼ˆ0ï¼Œ1ï¼‰æ­£æ€åˆ†å¸ƒçš„éšæœºæ•°ï¼Œä½œä¸ºåˆå¹¶è®¢å•çš„å‚æ•°
            df_orders['combine_flag'] = np.random.normal(0, 1, size=df_orders.shape[0])

            print('row of df_orders is ', len(df_orders))

            # è°ƒç”¨è®¢å•åˆå¹¶å‡½æ•°
            print('Combinging Orders ... ')
            df_orders_combined = sales_orders(df_orders)

            # QA
            print('row of df_orders_combined is ', len(df_orders_combined))

            # 10.2 æ‹†åˆ†ä¸ºäº¤æ˜“è¡¨å’Œäº¤æ˜“æ˜ç»†è¡¨
            # sales_order_details
            df_sales_order_details = df_orders_combined[['order_key','product_key','adj_quantity','adj_price','adj_sales','promo_key','date']]
            df_sales_order_details.rename(columns={'adj_quantity': 'quantity','adj_price': 'unit_price','adj_sales':'sales'}, inplace=True)
            print('row of df_sales_order_details is ', len(df_sales_order_details))

            # sales_order
            df_sales_order = df_orders_combined[['order_key','customer_key','date']].groupby(['order_key'],as_index=False).max()
            print('row of sales_order is ', len(df_sales_order))

            # 10.3 å†™å…¥æ•°æ®åº“
            rows_sales_order_details = InsertSalesData(oridata, dp_t14, refresh_dt, df_sales_order_details)
            print(" Inserted {0} rows of sales data into {1} on {2}".format(rows_sales_order_details, dp_t14, refresh_dt))
            
            rows_sales_order = InsertSalesData(oridata, dp_t15, refresh_dt, df_sales_order)
            print(" Inserted {0} rows of sales data into {1} on {2}".format(rows_sales_order, dp_t15, refresh_dt))

            # PART 12 ======================================================================================
            # ç½‘é¡µæµè§ˆè¡¨
            # ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§

            # ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§
            print("Dataframes production for {0} ends".format(refresh_dt))
            print("#############################################")

        else:
            print("Inventory table is not ready for ", refresh_dt)
            break

        refresh_dt=refresh_dt + timedelta(days = 1)
    
    # è°ƒè¯•å¤šå¤©
    return df_visits, df_sales_order, rows_sales_order_details, df_allp_invt_Comb


def checkTableExists(engine, tablename):  # check if sales_order exists #tested

    sql="""
        SELECT COUNT(*) as ct
        FROM information_schema.tables
        WHERE table_name = '{0}'
        """.format(tablename)

    count=pd.read_sql(sql, engine)

    if count['ct'][0] == 1:
        print(tablename, "exits")
        return True

    else:
        print(tablename, "does not exit")
        return False


def findRefresh_dt(engine, tablename, dtkey):  # find refresh date #working

    if checkTableExists(engine, tablename):
        sql="""
            SELECT max({0}) as max_dt
            FROM {1}
            """.format(dtkey, tablename)

        df_maxdt=pd.read_sql(sql, engine)

        if pd.isnull(df_maxdt['max_dt'][0]):
            refresh_dt=start_dt
        else:    
            refresh_dt=df_maxdt['max_dt'][0] + timedelta(days = 1)
            refresh_dt = refresh_dt.date()
            print("refresh_dt is {0}".format(refresh_dt))
            # print("type of refresh_dt is {0}".format(type(refresh_dt)))

    else:
        refresh_dt=start_dt

    return refresh_dt


def findMax_dt(engine, tablename, dtkey):  # find max date in the table #working

    if checkTableExists(engine, tablename):
        sql="""
            SELECT max({0}) as max_dt
            FROM {1}
            """.format(dtkey, tablename)

        df_maxdt=pd.read_sql(sql, engine)

        maxdt=df_maxdt['max_dt'][0]

    return maxdt


def cust_seg(customer, current_date):

    # æ²¡æœ‰closeæˆ–è€…returnçš„é¡¾å®¢ï¼Œå°†æ—¶é—´å­—æ®µèµ‹äºˆ0001-01-01ï¼Œä»¥ä¾¿æ¯”è¾ƒ
    customer=customer.fillna(date(1, 1, 1))

    customer=customer.loc[customer['cust_first_order_date'] <= current_date]
    customer=customer.loc[customer['close_date'] <= current_date]
    customer=customer.loc[customer['return_date'] <= current_date]

    max_id=customer['id'].groupby(customer['customer_key']).max()
    max_id=pd.DataFrame(max_id)
    max_id=max_id.reset_index(drop = True)

    cust_date=pd.merge(max_id, customer, how = 'left',
                         left_on = 'id', right_on = 'id')

    i=0
    lista=[]

    while i < len(cust_date):

        # æå–å‡ºæ¯ä¸ªé¡¾å®¢ç›¸åº”çš„æ—¶é—´æ•°æ®
        fd=cust_date['cust_first_order_date'][i]
        cd=cust_date['close_date'][i]
        rd=cust_date['return_date'][i]

        # ç­›é€‰cdå’Œrdæ˜¯0001-01-01çš„é¡¾å®¢ï¼Œå³è¿˜æ²¡æœ‰closeæˆ–è€…returnçš„
        if fd >= cd and fd >= rd:

            # é¦–æ¬¡è´­ä¹°æ—¥æœŸè·ç¦»current_dateåœ¨30å¤©ä¹‹å†…çš„è®¤å®šä¸ºæ–°é¡¾å®¢
            if fd >= (current_date - timedelta(days=30)):  
                lista.append('New')

            else:  # å…¶ä½™çš„è®¤å®šä¸ºç§¯æé¡¾å®¢
                lista.append('Reactive')

        # close_dateæœ€å¤§çš„é¡¾å®¢åˆ¤æ–­ä¸ºæµå¤±é¡¾å®¢
        elif cd > fd and cd > rd:  
            lista.append('Close')
        
        # å…¶ä½™çš„åˆ¤å®šä¸ºå›æµé¡¾å®¢
        else:  
            lista.append('Return')

        i=i + 1

    cust_date['cust_status']=lista
    cust_status=cust_date[['customer_key', 'cust_status']]

    return cust_status


def fbm_modify(row):

    if row['cust_status'] == 0:

        return -1

    else:

        return row['first_buy_mark']


def trans_into_dict(row_value):

    if row_value == None:
        return None

    elif pd.isnull(row_value):
        return None

    else:
        return eval(row_value)



def promo_affects(row):

    # fixed_cart
    if row['discount_type'] == 'fixed_cart':

        if row['sales'] >= row['fcp_treatment']['full']:

            row['adj_sales'] = row['sales'] - row['fcp_treatment']['minus']

        else:
            row['adj_sales'] = row['sales']

        row['adj_quantity'] = row['quantity']

    # percent
    elif row['discount_type'] == 'percent':

        row['adj_sales'] = row['sales'] * row['pp_treatment']

        row['adj_quantity'] = row['quantity']

    # bogo
    elif row['discount_type'] == 'bogo':

        row['adj_sales'] = row['sales']

        # é™¤æ³•å–æ•´
        quotient = row['quantity'] // row['bp_treatment']['buy']

        # åŸå§‹æˆäº¤é‡æ˜¯Qä»¶ï¼Œä¹°xé€y, Q//x å–æ•´å¾—quotï¼Œè°ƒæ•´åæˆäº¤é‡ = Q + quot * y
        row['adj_quantity'] = row['quantity'] + \
            quotient * row['bp_treatment']['get free']

    # multibuy
    elif row['discount_type'] == 'multibuy':

        # é™¤æ³•å–æ•´
        quotient = row['quantity'] // row['mp_treatment']['quantity']

        # é™¤æ³•å–ä½™
        remainder = row['quantity'] % row['mp_treatment']['quantity']

        if quotient >= 1:
            row['adj_sales'] = quotient * \
                row['mp_treatment']['price'] + remainder * row['price']

        else:
            row['adj_sales'] = row['sales']

        row['adj_quantity'] = row['quantity']

    # xxoff
    elif row['discount_type'] == 'xxoff':

        row['adj_sales'] = row['sales'] - row['xp_treatment']

        row['adj_quantity'] = row['quantity']

    # nullå€¼ï¼Œæ²¡æœ‰ä¿ƒé”€å·
    else:
        row['adj_sales'] = row['sales']

        row['adj_quantity'] = row['quantity']

    return row




def score_cs(row_value):

    if row_value == 'New':
        return abs(np.random.normal(1, 0.1))

    elif row_value == 'Reactive':
        return abs(np.random.normal(1, 0.05))

    elif row_value == 'Return':
        return abs(np.random.normal(1.1, 0.1))

    else:
        return 0


def score_prom(row_value):

    if pd.isnull(row_value):
        return abs(np.random.normal(1, 0.05))

    elif row_value == None:
        return abs(np.random.normal(1, 0.05))

    else:
        return abs(np.random.normal(0.7, 0.1))


def buy_score(row):

    #  è¯¥é¡¾å®¢ç¬¬ä¸€æ¬¡è´­ä¹°
    if row['first_buy_mark'] == 1:
        return 1
    
    #  è¯¥é¡¾å®¢ä¸æ˜¯ç¬¬ä¸€æ¬¡è´­ä¹°
    elif row['first_buy_mark'] == 0:

        # è®¡ç®—æ”¾å¼ƒåˆ†
        score = row['score_flag'] * row['score_cs'] * row['score_prom']

        # æ¯”è¾ƒé¡¾å®¢å¿ è¯šåº¦å’Œæ”¾å¼ƒåˆ†ï¼Œå¦‚æœåˆ†æ•°æ²¡æœ‰è¶…è¿‡é¡¾å®¢å¿ è¯šåº¦ï¼Œåˆ™è´­ä¹°åˆ†æ•°ä¸º-1
        if row['cust_loyalty'] >= score:

            #å¦‚æœè¯¥äº§å“å·²ä¸Šæ¶
            if row['price'] != 0:
                return -1

            #å¦‚æœè¯¥äº§å“æœªä¸Šæ¶
            else:
                return 0
        
        # æ”¾å¼ƒåˆ†è¶…è¿‡é¡¾å®¢å¿ è¯šåº¦ï¼Œè´­ä¹°åˆ†æ•°ä¸º0
        else:
            return 0

    # è¯¥é¡¾å®¢è¿™æ¬¡ä¸èƒ½è´­ä¹°ï¼Œrow['first_buy_mark'] == -1
    else:
        return 0



def buy_decision(tbl):

    list_cs = []

    tbl['score_flag'] = np.random.random(tbl.shape[0])

    tbl['score_cs'] = tbl['cust_status'].apply(score_cs)

    tbl['score_prom'] = tbl['promo_key'].apply(score_prom)

    tbl['cust_loyalty'] = tbl['cust_loyalty'].astype(float)

    tbl['buy_score'] = tbl.apply(lambda row: buy_score(row), axis=1)

    return tbl


def randomTimeStamp(refresh_dt, number):

    start_year = refresh_dt.year
    start_month = refresh_dt.month
    start_day = refresh_dt.day
    stop_year = refresh_dt.year
    stop_month = refresh_dt.month
    stop_day = refresh_dt.day

    # è®¾ç½®å¼€å§‹æ—¥æœŸæ—¶é—´å…ƒç»„ï¼ˆå¦‚ 1976-01-01 00ï¼š00ï¼š00ï¼‰
    a1 = (start_year, start_month, start_day, 0, 0, 0,
          0, 0, 0)
    # è®¾ç½®ç»“æŸæ—¥æœŸæ—¶é—´å…ƒç»„ï¼ˆå¦‚ 1990-12-31 23ï¼š59ï¼š59ï¼‰
    a2 = (stop_year, stop_month, stop_day, 23, 59, 59,
          0, 0, 0)

    # ç”Ÿæˆå¼€å§‹æ—¶é—´æˆ³
    start = time.mktime(a1)
    # ç”Ÿæˆç»“æŸæ—¶é—´æˆ³
    end = time.mktime(a2)

    # éšæœºç”Ÿæˆnä¸ªæ—¥æœŸå­—ç¬¦ä¸²
    random_timestamp = []

    for i in range(number):

        # åœ¨å¼€å§‹å’Œç»“æŸæ—¶é—´æˆ³ä¸­éšæœºå–å‡ºä¸€ä¸ª
        t = random.randint(start, end)

        # å°†æ—¶é—´æˆ³ç”Ÿæˆæ—¶é—´å…ƒç»„
        date_touple = time.localtime(t)

        # å°†æ—¶é—´å…ƒç»„è½¬æˆæ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ˆ1976-05-21ï¼‰
        # date = time.strftime("%Y-%m-%d %H:%M:%S", date_touple)
        date = time.strftime("%H:%M:%S", date_touple)
        random_timestamp.append(date)

    # type(random_timestamp) is list, elements in this list are strings with ''
    return(random_timestamp)


def fetchAllp_invtInfo(engine, tablename_1, dtkey_1, tablename_2, dtkey_2, invt_dt):

    # åº“å­˜è¡¨
    sql_1 = """
        SELECT *
        FROM {0}
        WHERE {1} = '{2}'
        """.format(tablename_1, dtkey_1, invt_dt)

    df_invt = pd.read_sql(sql_1, engine)

    # åº“å­˜äº¤æ˜“è¡¨
    sql_2 = """
        SELECT *
        FROM {0}
        WHERE {1} = '{2}' AND transaction_type = 'purchase'
        """.format(tablename_2, dtkey_2, invt_dt)

    df_invt_trans = pd.read_sql(sql_2, engine)

    return df_invt, df_invt_trans


def fetchBalance(row, df_allp_invt_Comb, df_department, df_price):

    # print("row begins...............")
    # print("product_key is", row['product_key'])

    # æœ‰è´­ä¹°æ„å‘çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬ä¸¤ç§äººï¼Œ1ä¸ºå¿…é¡»è´­ä¹°æˆåŠŸï¼Œ-1ä¸ºä¸å¿…è´­ä¹°æˆåŠŸ
    if row['buy_score'] != 0:
        # print("æœ‰è´­ä¹°æ„å‘")

        while True:

            if row['department_cd'] == 34 or row['department_cd'] == 37:
                BK = 'TransBalance'

            else:
                BK = 'CombinedBalance'

            dq = row['adj_quantity']
            iq = df_allp_invt_Comb.loc[df_allp_invt_Comb['Product_key'] ==
                                       row['product_key'], [BK]][BK].iloc[0]

            # èƒ½ç›´æ¥æ»¡è¶³
            if dq <= iq:

                row['trans_quantity'] = dq

                df_allp_invt_Comb.loc[df_allp_invt_Comb['Product_key'] ==
                                      row['product_key'], BK] = iq - row['trans_quantity']

                row['trans_done'] = 1

            # ä¸èƒ½ç›´æ¥æ»¡è¶³
            else:

                # è¿˜æœ‰åº“å­˜:æˆåŠŸ
                if iq != 0:

                    row['trans_quantity'] = iq

                    df_allp_invt_Comb.loc[df_allp_invt_Comb['Product_key']
                                          == row['product_key'], BK] = 0

                    row['trans_done'] = 1

                # æ²¡æœ‰åº“å­˜äº†
                else:

                    # å¿…é¡»è´­ä¹°
                    if row['buy_score'] == 1:

                        row['trans_quantity'] = 0
                        row['trans_done'] = 0

                    # éå¿…é¡»è´­ä¹°
                    else:

                        row['trans_quantity'] = 0
                        row['trans_done'] = 0

            # å¦‚æœå¿…é¡»è´­ä¹°çš„äººæ²¡æœ‰æˆåŠŸï¼Œç»§ç»­å¾ªç¯ï¼Œæ›´æ¢äº§å“ã€éƒ¨é—¨å’Œéœ€æ±‚é‡ï¼Œæ›´æ–°ä¿ƒé”€ä¿¡æ¯ï¼Œæ›´æ–°é”€é‡ã€ä»·æ ¼å’Œé”€å”®é¢
            # å¦åˆ™å¯ä»¥ç»ˆæ­¢å¾ªç¯
            if row['buy_score'] == 1 and row['trans_done'] == 0:

                # change Product_key, åªèƒ½åœ¨å·²ç»ä¸Šæ¶çš„äº§å“ä¸­å¯»æ‰¾
                row['product_key'] = int(
                    df_price['product_key'].sample().iloc[0])
                # change department_cd
                row['department_cd'] = df_department.loc[df_department['product_key'] ==
                                                             row['product_key'], ['department_cd']]['department_cd'].iloc[0]
                # change adj_quantity,price,adj_sales
                row['adj_quantity'] = 1
                row['price'] = df_price.loc[df_price['product_key'] ==
                                            row['product_key'], ['price']]['price'].iloc[0]
                row['adj_sales'] = row['adj_quantity'] * row['price']

                continue

            else:
                # ct = ct + 1
                break

        return row

    # æ— è´­ä¹°æ„å‘çš„è¡Œä¸ºï¼Œä¸éœ€æ›´æ”¹
    else:

        return row



def orderGenerate(tbl, refresh_dt, df_department, df_price):

    # ä¸€ã€éœ€æ±‚è¡¨å‡†å¤‡
    df = tbl.copy()
    # æ‰“ä¸Šéšæœºæ—¶é—´æˆ³ï¼Œå¹¶æŒ‰æ—¶é—´å…ˆåæ’åºï¼Œåˆå§‹åŒ–trans_done,CombinedBalance,TransBalance
    time_stamp = randomTimeStamp(refresh_dt, len(df))
    df['time_stamp'] = time_stamp
    df.sort_values(by='time_stamp', ascending=True, inplace=True)
    df['visit_key'] = range(1, len(df) + 1)
    df['trans_done'] = 0
    df['trans_quantity'] = 0
    df = df.reset_index(drop=True)
    # adding a dummy row to deal with df.apply() which is designed to run twice on first row/column
    df.loc[-1] = df.iloc[0]
    df['buy_score'].loc[-1] = 0  # critical
    df.index = df.index + 1  # shifting index
    df.sort_index(inplace=True)
    print('df is Ready ', len(df))

    # äºŒã€åº“å­˜è¡¨å‡†å¤‡
    # åº“å­˜æ—¥ä¸ºåˆ·æ–°æ—¥çš„å‰ä¸€å¤©ï¼šæ˜¯å¦èƒ½æˆäº¤éœ€è¦æ£€æŸ¥çš„æ˜¯å‰ä¸€å¤©çš„åº“å­˜å’Œå‰ä¸€å¤©çš„å¤‡è´§
    invt_dt = refresh_dt - timedelta(days=1)

    # 1.1 æŠ“å–æ‰€æœ‰äº§å“ åº“å­˜æ—¥(åˆ·æ–°æ—¥å‰ä¸€å¤©) çš„ é™æ€ åˆå¹¶åº“å­˜CombinedBalance å’Œ å¤‡è´§åº“å­˜TransBalance
    df_allp_invt, df_allp_invt_trans = fetchAllp_invtInfo(
        oridata, dp_t8, dp_t8_dtkey, dp_t9, dp_t9_dtkey, invt_dt)

    # 1.2 åˆå¹¶ df_allp_invt å’Œ df_allp_invt_trans
    print('merging df_allp_invt and df_allp_invt_trans into df_allp_invt_Comb... ')
    df_allp_invt_Comb = pd.merge(df_allp_invt, df_allp_invt_trans[[
                                 'product_key', 'quantity']], how='outer', left_on='Product_key', right_on='product_key')
    # QA
    if len(df_allp_invt_Comb) == len(df_allp_invt) + len(df_allp_invt_trans) - len(set(df_allp_invt['Product_key']) & set(df_allp_invt_trans['product_key'])):
        pass
    else:
        print("WARNING 1: df_allp_invt_Comb QA is WRONG !!!!!!!  PLEASE CHECK !!!!!!!!!! ")
    # print('row of df_allp_invt_Comb is ', len(df_allp_invt_Comb))
    # å¡«å……Quantity å’Œ quantity ç¼ºå¤±å€¼ï¼Œå¾—åˆ° åˆå¹¶åº“å­˜CombinedBalance å’Œ å¤‡è´§åº“å­˜TransBalance
    df_allp_invt_Comb = df_allp_invt_Comb.fillna(
        {'Quantity': 0, 'quantity': 0})
    df_allp_invt_Comb['CombinedBalance'] = df_allp_invt_Comb['Quantity'] + \
        df_allp_invt_Comb['quantity']
    df_allp_invt_Comb['TransBalance'] = df_allp_invt_Comb['quantity']
    # å¡«å…… Product_key ç¼ºå¤±å€¼,åˆ é™¤å¤šä½™çš„productåˆ—
    df_allp_invt_Comb['Product_key'] = np.where(np.isnan(
        df_allp_invt_Comb['Product_key']), df_allp_invt_Comb['product_key'], df_allp_invt_Comb['Product_key'])
    df_allp_invt_Comb.drop(['product_key'], axis=1, inplace=True)

    # 1.3 åˆå¹¶ df_allp_invt_Comb å’Œ df_demand_pkï¼ˆéœ€æ±‚äº§å“ï¼‰
    series_demand_pk = df['product_key'].drop_duplicates()
    df_demand_pk = pd.DataFrame(series_demand_pk, columns=['product_key'])
    print('merging demand products to df_allp_invt_Comb ... ')
    len_bf_merge = len(df_allp_invt_Comb)
    set_bf_merge = set(df_allp_invt_Comb['Product_key'])
    df_allp_invt_Comb = pd.merge(df_allp_invt_Comb, df_demand_pk[[
                                 'product_key']], how='outer', left_on='Product_key', right_on='product_key')
    # QA
    if len(df_allp_invt_Comb) == len_bf_merge + len(df_demand_pk) - len(set_bf_merge & set(df_demand_pk['product_key'])):
        pass
    else:
        print("WARNING 2: df_allp_invt_Comb QA is WRONG !!!!!!!  PLEASE CHECK !!!!!!!!!! ")
    # print('row of df_allp_invt_Comb is ', len(df_allp_invt_Comb))
    # å¡«å……CombinedBalance å’Œ TransBalanceç¼ºå¤±å€¼
    df_allp_invt_Comb = df_allp_invt_Comb.fillna(
        {'CombinedBalance': 0, 'TransBalance': 0})
    # å¡«å…… Product_key ç¼ºå¤±å€¼,åˆ é™¤å¤šä½™çš„productåˆ—
    df_allp_invt_Comb['Product_key'] = np.where(pd.isnull(
        df_allp_invt_Comb['Product_key']), df_allp_invt_Comb['product_key'], df_allp_invt_Comb['Product_key'])
    df_allp_invt_Comb.drop(['product_key'], axis=1, inplace=True)

    # 1.4 åˆå¹¶ df_allp_invt_Comb å’Œ df_prodOnline_pkï¼ˆä¸Šæ¶äº§å“ï¼‰
    # ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§
    series_prodOnline_pk = df_price['product_key'].drop_duplicates()
    df_prodOnline_pk = pd.DataFrame(series_prodOnline_pk, columns=['product_key'])
    print('merging online products to df_allp_invt_Comb ... ')
    len_bf_merge = len(df_allp_invt_Comb)
    set_bf_merge = set(df_allp_invt_Comb['Product_key'])
    df_allp_invt_Comb = pd.merge(df_allp_invt_Comb, df_prodOnline_pk[[
                                 'product_key']], how='outer', left_on='Product_key', right_on='product_key')
    # QA
    if len(df_allp_invt_Comb) == len_bf_merge + len(df_prodOnline_pk) - len(set_bf_merge & set(df_prodOnline_pk['product_key'])):
        pass
    else:
        print("WARNING 3: df_allp_invt_Comb QA is WRONG !!!!!!!  PLEASE CHECK !!!!!!!!!! ")
    # print('row of df_allp_invt_Comb is ', len(df_allp_invt_Comb))
    # å¡«å……CombinedBalance å’Œ TransBalanceç¼ºå¤±å€¼
    df_allp_invt_Comb = df_allp_invt_Comb.fillna(
        {'CombinedBalance': 0, 'TransBalance': 0})
    # å¡«å…… Product_key ç¼ºå¤±å€¼,åˆ é™¤å¤šä½™çš„productåˆ—
    df_allp_invt_Comb['Product_key'] = np.where(pd.isnull(
        df_allp_invt_Comb['Product_key']), df_allp_invt_Comb['product_key'], df_allp_invt_Comb['Product_key'])
    df_allp_invt_Comb.drop(['product_key'], axis=1, inplace=True)
    # ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§ ğŸš§

    # 1.5 é“¾æ¥ department_cd åˆ° df_allp_invt_Comb
    print('merging department to df_allp_invt_Comb ... ')
    df_allp_invt_Comb = pd.merge(df_allp_invt_Comb, df_department,
                                 how='left', left_on='Product_key', right_on='product_key')
    # åˆ é™¤å¤šä½™çš„productåˆ—
    df_allp_invt_Comb.drop(['product_key'], axis=1, inplace=True)
    # QA
    print('df_allp_invt_Comb is Ready, number of rows is ', len(df_allp_invt_Comb))

    # ä¸‰ã€ç”Ÿæˆè®¢å•
    tqdm.pandas()
    print('Generating Orders ... ')
    df = df.progress_apply(lambda row: fetchBalance(row, df_allp_invt_Comb,df_department,df_price), axis=1)
    # deleting the dummy row that was added before to avoid twice run on first row
    df = df.iloc[1:]

    return df, df_allp_invt_Comb


def to_integer(dt_time):

    return 10000*dt_time.year + 100*dt_time.month + dt_time.day


def orderkey(row):

    x = int(str(row['dt_key'])[2:])

    y = row['visit_key']

    a = math.floor(math.log10(y))

    return int(x*10**(1+a)+y)


def sales_orders(df_orders):

    # æ‰¾å‡ºæ‰€æœ‰ customer_key
    df_ck = df_orders['customer_key'].drop_duplicates()
    df_ck = df_ck.reset_index(drop=True)

    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„DataFrame
    df_allc = pd.DataFrame()

    # å¯¹äºæ‰€æœ‰çš„ customer_key,æŒ‰é¡ºåºå–å‡ºæ¯ä¸€ä¸ªkey
    for i in tqdm(range(len(df_ck))):

        # get one customer's key
        ck = df_ck[i]

        # fetch all recourds of this customer
        df_oc = deepcopy(df_orders.loc[df_orders['customer_key'] == ck, :])
        df_oc = df_oc.reset_index(drop=True)

        # åˆå§‹åŒ–flag_ct
        flag_ct = 0

        # ç»Ÿè®¡ combine_flag <=2 (ä¸¤ä¸ªæ ‡å‡†å·®å·¦ä¾§çš„é¢ç§¯) çš„è¡Œæ•°
        for j in range(len(df_oc)):

            if df_oc['combine_flag'][j] <= 2:

                flag_ct += 1

        # åˆ¤æ–­ combine_flag <=2çš„è¡Œæ•° æ˜¯å¦å¤§äº1
        if flag_ct > 1:

            # è·å–combine_flag <=2 è¡Œæ•° çš„ æœ€å¤§order_key
            df_flag_ct = deepcopy(df_oc.loc[df_oc['combine_flag'] <= 2, :])
            max_orderkey = df_flag_ct['order_key'].max()

            # åœ¨è¯¥é¡¾å®¢çš„è®°å½•ä¸­ï¼Œå°† combine_flag <=2 çš„è®°å½•çš„order_key ä¿®æ”¹ä¸ºæœ€å¤§order_key,å‰©ä½™éƒ¨åˆ†ä¸å˜
            df_oc['order_key'] = np.where(
                df_oc['combine_flag'] <= 2, max_orderkey, df_oc['order_key'])

        # å°† df_op appendåˆ° df_allp
        df_allc = df_allc.append(df_oc)

    return df_allc


def InsertSalesData(engine, tablename, refresh_dt, df):

    # æŸ¥è¯¢å½“å¤©æ˜¯å¦å·²ç»æœ‰é”€å”®æ•°æ®
    count = pd.read_sql(
        """ SELECT COUNT(*) as ct FROM {0} WHERE date = '{1}' """.format(tablename, refresh_dt), engine)

    # å¦‚æœå½“å¤©å·²ç»æœ‰é”€å”®æ•°æ®ï¼Œåˆ é™¤æ‰
    if count['ct'][0] != 0:
        print("Deleting sales data from {0} on {1}".format(tablename, refresh_dt))
        with engine.begin() as conn:
            conn.execute(""" DELETE FROM {0} WHERE date = '{1}' """.format(tablename, refresh_dt))

    # æ’å…¥å½“å¤©é”€å”®æ•°æ®
    print("Inserting sales data into {0} on {1}".format(tablename, refresh_dt))
    df.to_sql('{0}'.format(tablename),if_exists='append', con=engine, index=False)

    # æŸ¥è¯¢å½“å¤©é”€å”®æ•°æ®
    result = engine.execute(
        """SELECT COUNT(*) as ct FROM {0} WHERE date = '{1}' """.format(tablename, refresh_dt)).fetchall()

    return result



# main program
if __name__ == '__main__':

    # df_visits, df_sales_order, rows_sales_order_details,df_allp_invt_Comb = main()
    
    try:
        df_visits, df_sales_order, rows_sales_order_details,df_allp_invt_Comb = main()
    except UnboundLocalError:
        print("Please try later.Or you can delete the last day sales data to test again. ")


time_end=time.time()
print('End at', time.strftime("%H:%M:%S") )
print('totally cost',(time_end-time_start)/60, 'mins')
print('#############################################')